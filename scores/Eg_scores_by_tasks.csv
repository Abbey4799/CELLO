model_name,extraction,Planning,meta_prompt,brainstorming_single_round,writing_single_round,Ave_complex_ins,keywords_extraction,closed_qa,Summarization,Structure,brainstorming_multi_rounds,writing_multi_rounds,Ave_complex_input,Average
Llama2-chat-7B,0.495,0.326,0.5,0.358,0.465,0.429,0.157,0.135,0.06,0.708,0.541,0.447,0.341,0.385
Llama2-chat-70B,0.431,0.289,0.484,0.397,0.472,0.415,0.147,0.158,0.079,0.719,0.57,0.552,0.371,0.393
Llama2-chat-13B,0.445,0.329,0.624,0.359,0.453,0.442,0.154,0.127,0.108,0.753,0.569,0.458,0.361,0.402
Vicuna-V1.3-7B,0.485,0.661,0.303,0.748,0.665,0.573,0.18,0.651,0.583,0.525,0.674,0.773,0.564,0.569
WizardLM,0.422,0.592,0.281,0.675,0.856,0.565,0.261,0.594,0.57,0.519,0.711,0.839,0.582,0.574
LongChat-V1-13B,0.523,0.591,0.423,0.654,0.533,0.545,0.4,0.572,0.532,0.579,0.752,0.81,0.607,0.576
LongChat-V1.5-7B,0.489,0.62,0.358,0.664,0.731,0.572,0.608,0.687,0.633,0.378,0.747,0.825,0.646,0.609
LongChat-V1-7B,0.549,0.475,0.424,0.71,0.805,0.593,0.527,0.604,0.557,0.692,0.729,0.856,0.661,0.627
Vicuna-V1.3-13B,0.521,0.625,0.474,0.743,0.84,0.641,0.346,0.672,0.582,0.613,0.651,0.869,0.622,0.631
Vicuna-V1.5-7B,0.544,0.67,0.398,0.506,0.77,0.578,0.711,0.739,0.667,0.513,0.693,0.906,0.705,0.641
Vicuna-V1.3-33B,0.589,0.702,0.385,0.752,0.835,0.653,0.503,0.68,0.643,0.627,0.622,0.872,0.658,0.655
Vicuna-V1.5-13B,0.601,0.721,0.425,0.744,0.794,0.657,0.682,0.765,0.723,0.63,0.746,0.896,0.74,0.699
OpenChat-V3.2,0.629,0.733,0.51,0.754,0.868,0.699,0.725,0.771,0.663,0.608,0.761,0.919,0.741,0.72
GPT-3.5-turbo,0.709,0.805,0.632,0.879,0.854,0.776,0.765,0.795,0.832,0.697,0.879,0.908,0.813,0.794
GPT-4,0.737,0.879,0.666,0.828,0.81,0.784,0.862,0.889,0.911,0.727,0.867,0.91,0.861,0.822
